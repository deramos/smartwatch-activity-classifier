{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f35a3f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, FloatType, StringType, TimestampType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "236aab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables \n",
    "BUCKET_NAME = os.getenv('BUCKET', 's3n://apple-watch-activity-data')\n",
    "SOURCE_DIR = os.getenv('PROCESSED_PATH', 'data/processed')\n",
    "DB_NAME = os.getenv('DB_NAME', 'watchdata')\n",
    "TABLE_NAME = os.getenv('TABLE_NAME', 'activitydata')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7338f93",
   "metadata": {},
   "source": [
    "## Spark Session and AWS Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69c448e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set SPARK SUBMIT ARGS for \n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages: org.apache.spark:spark-hadoop-cloud_2.12:3.2.0'\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = \"--master local[*] pyspark-shell\"\n",
    "\n",
    "# Create Spark Session\n",
    "spark = SparkSession\\\n",
    "    .builder \\\n",
    "    .config('spark.jars.packages', 'org.apache.hadoop:hadoop-aws:3.2.0,org.apache.hadoop:hadoop-client:3.2.0') \\\n",
    "    .config('spark.jars.packages', 'org.apache.spark:spark-hadoop-cloud_2.12:3.2.0') \\\n",
    "    .config('spark.hadoop.fs.s3.impl', 'org.apache.hadoop.fs.s3a.S3AFileSystem') \\\n",
    "    .config('spark.jars.excludes', 'com.google.guava:guava') \\\n",
    "    .appName(\"train-activity-model\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set AWS KEY\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", \"\")\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a412079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abc1b45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hadoop version = 3.3.4\n"
     ]
    }
   ],
   "source": [
    "print(f\"Hadoop version = {spark.sparkContext._jvm.org.apache.hadoop.util.VersionInfo.getVersion()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d2cfba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data schema\n",
    "schema = StructType([\n",
    "    StructField(\"stamp\", TimestampType(), nullable=True),\n",
    "    StructField(\"yaw\", FloatType(), nullable=True),\n",
    "    StructField(\"pitch\", FloatType(), nullable=True),\n",
    "    StructField(\"roll\", FloatType(), nullable=True),\n",
    "    StructField(\"rotation_rate_x\", FloatType(), nullable=True),\n",
    "    StructField(\"rotation_rate_y\", FloatType(), nullable=True),\n",
    "    StructField(\"rotation_rate_z\", FloatType(), nullable=True),\n",
    "    StructField(\"user_acceleration_x\", FloatType(), nullable=True),\n",
    "    StructField(\"user_acceleration_y\", FloatType(), nullable=True),\n",
    "    StructField(\"user_acceleration_z\", FloatType(), nullable=True),\n",
    "    StructField(\"location_type\", StringType(), nullable=True),\n",
    "    StructField(\"latitude_distance_from_mean\", FloatType(), nullable=True),\n",
    "    StructField(\"longitude_distance_from_mean\", FloatType(), nullable=True),\n",
    "    StructField(\"altitude_distance_from_mean\", FloatType(), nullable=True),\n",
    "    StructField(\"course\", FloatType(), nullable=True),\n",
    "    StructField(\"speed\", FloatType(), nullable=True),\n",
    "    StructField(\"horizontal_accuracy\", FloatType(), nullable=True),\n",
    "    StructField(\"vertical_accuracy\", FloatType(), nullable=True),\n",
    "    StructField(\"battery_state\", StringType(), nullable=True),\n",
    "    StructField(\"user_activity_label\", StringType(), nullable=True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b9a45a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark \\\n",
    "    .read \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .parquet(f\"{BUCKET_NAME}/{SOURCE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3429b469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1012"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd97a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = data.filter(\"user_activity_label is not null\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82b6fca",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9918bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_cols = ['location_type', 'battery_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f5e5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_indexer = StringIndexer(inputCols=string_cols, outputCols=[s+'_indexed' for s in string_cols])\n",
    "string_indexer_model = string_indexer.fit(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
